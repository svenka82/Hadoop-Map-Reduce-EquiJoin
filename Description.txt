Mapper : Mapper works on each row of the input file, splits it based on comma, and considers the second field of the row as the key which is effectively the index 1 since index starts from 0. They key acts as the join column for the reduce task where we combine records.

Reducer : Reducer works on (key,list of values), segregates rows based on the relation. This is done by comparing the first field which holds the relation name after splitting row based on comma. The rows are added to corresponding lists. So we have two lists, one for each of the relation. Reducer then for each row in one relation, it iterates over all the rows of other relation and just combines the rows. We need not check anything here because the MapReduce framework would have already grouped rows based on key. So all rows having same join column will be already grouped, we need to just combine rows of relations for which we have already computed two lists. 

Driver : Driver instantiates the JobConfiguration instance and sets the necessary parameters for the Map and Reduce task. Its sets the output key class, value class and also sets input and output path which we get from command line arguments. It then initiates the map reduce job.
